{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# 06 — Data Science Report: MMM Technical Validation\n",
    "\n",
    "This report provides a consolidated technical view of the fitted Marketing Mix Model for review by the data science team. It loads the most recently saved model trace from `outputs/models/` and reproduces all key diagnostics, convergence checks, and channel analysis without re-running MCMC sampling. The intended audience is data scientists and ML engineers who need to assess model quality, understand parameter posteriors, and evaluate the reliability of channel attribution results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-toc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup & Imports](#1-setup--imports)\n",
    "2. [Model Specification](#2-model-specification)\n",
    "3. [Convergence Diagnostics](#3-convergence-diagnostics)\n",
    "4. [Trace Plots](#4-trace-plots)\n",
    "5. [Posterior Predictive Check](#5-posterior-predictive-check)\n",
    "6. [Prior vs Posterior](#6-prior-vs-posterior)\n",
    "7. [Channel Decomposition](#7-channel-decomposition)\n",
    "8. [Adstock Decay Curves](#8-adstock-decay-curves)\n",
    "9. [Saturation Response Curves](#9-saturation-response-curves)\n",
    "10. [Model Limitations](#10-model-limitations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.special import expit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from pymc_marketing.mmm import MMM\n",
    "\n",
    "from mmm_demo.config import OUTPUTS_DIR, ModelConfig\n",
    "from mmm_demo.data import load_mmm_weekly_data\n",
    "from mmm_demo.diagnostics import ESS_THRESHOLD, RHAT_THRESHOLD, check_convergence\n",
    "from mmm_demo.model import sample_posterior_predictive\n",
    "\n",
    "print(f\"ArviZ version:          {az.__version__}\")\n",
    "print(f\"RHAT_THRESHOLD:         {RHAT_THRESHOLD}\")\n",
    "print(f\"ESS_THRESHOLD:          {ESS_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Model Specification\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The model uses PyMC-Marketing's `MMM` class with two transformation layers applied to each channel's spend before it enters the linear predictor:\n",
    "\n",
    "**GeometricAdstock** — models the lagged carryover (memory) effect of advertising:\n",
    "$$x^{\\text{adstock}}_t = \\sum_{l=0}^{L} \\alpha^l \\cdot x_{t-l}$$\n",
    "where $\\alpha \\in (0, 1)$ is the per-channel decay parameter and $L$ is `adstock_max_lag`. Higher $\\alpha$ means a longer-lasting advertising effect.\n",
    "\n",
    "**LogisticSaturation** — models diminishing returns from increased spend:\n",
    "$$f(x) = \\beta \\cdot \\left(2 \\cdot \\sigma(\\lambda x) - 1\\right)$$\n",
    "where $\\sigma$ is the logistic sigmoid, $\\lambda$ controls steepness (higher = faster saturation), and $\\beta$ scales the channel's overall contribution magnitude. Inputs are MaxAbsScaled to $[0, 1]$ by PyMC-Marketing before this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weekly data\n",
    "df = load_mmm_weekly_data()\n",
    "config = ModelConfig()\n",
    "feature_cols = [config.date_column, *config.channel_columns, *config.control_columns]\n",
    "x = df[feature_cols]\n",
    "y = df[config.target_column]\n",
    "\n",
    "# Load most recent saved model\n",
    "model_dir = OUTPUTS_DIR / \"models\"\n",
    "model_files = sorted(model_dir.glob(\"mmm_fit_*.nc\"))\n",
    "if not model_files:\n",
    "    raise FileNotFoundError(\n",
    "        \"No saved model found in outputs/models/. Run notebook 02 first.\"\n",
    "    )\n",
    "\n",
    "model_path = model_files[-1]\n",
    "print(f\"Loading model: {model_path.name}\")\n",
    "mmm = MMM.load(str(model_path))\n",
    "idata = mmm.idata\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-spec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class and transformation types\n",
    "print(\"=\" * 55)\n",
    "print(\"MODEL CLASS & TRANSFORMATIONS\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Model class:       {type(mmm).__name__}\")\n",
    "print(f\"Adstock type:      {type(mmm.adstock).__name__} (l_max={mmm.adstock.l_max})\")\n",
    "print(f\"Saturation type:   {type(mmm.saturation).__name__}\")\n",
    "print()\n",
    "print(f\"Channel columns ({len(mmm.channel_columns)}):\")\n",
    "for ch in mmm.channel_columns:\n",
    "    print(f\"  {ch}\")\n",
    "print()\n",
    "print(f\"Control columns ({len(mmm.control_columns)}):\")\n",
    "for ctrl in mmm.control_columns:\n",
    "    print(f\"  {ctrl}\")\n",
    "print()\n",
    "print(\"Sampling hyperparameters:\")\n",
    "print(f\"  adstock_max_lag:   {config.adstock_max_lag}\")\n",
    "print(f\"  chains:            {config.chains}\")\n",
    "print(f\"  draws:             {config.draws}\")\n",
    "print(f\"  tune:              {config.tune}\")\n",
    "print(f\"  target_accept:     {config.target_accept}\")\n",
    "print(\"  init:              advi+adapt_diag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s2-priors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior distributions summary table\n",
    "model_config = config.get_model_config()\n",
    "\n",
    "prior_rows = []\n",
    "for param_name, prior_obj in model_config.items():\n",
    "    prior_rows.append({\"Parameter\": param_name, \"Prior\": str(prior_obj)})\n",
    "\n",
    "prior_df = pd.DataFrame(prior_rows).set_index(\"Parameter\")\n",
    "print(\"Prior distributions:\")\n",
    "print(prior_df.to_string())\n",
    "print()\n",
    "print(\n",
    "    \"Note: All channel inputs and the target are MaxAbsScaled to [0, 1] internally.\\n\"\n",
    "    \"Priors are calibrated for this scaled space.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Convergence Diagnostics\n",
    "\n",
    "MCMC inference is only valid when the sampler has converged — i.e., all chains are exploring the same region of the posterior. Three standard metrics are evaluated:\n",
    "\n",
    "| Metric | Threshold | Meaning if violated |\n",
    "|--------|-----------|--------------------|\n",
    "| **R-hat** | < 1.01 | Chains disagree — parameter not identified |\n",
    "| **ESS (bulk)** | > 400 | Too few independent samples — estimates unreliable |\n",
    "| **Divergences** | = 0 | Sampler hit a pathological region of the posterior |\n",
    "\n",
    "Any failure should be understood before interpreting channel contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = check_convergence(idata)\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(\"CONVERGENCE DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Overall:      {'PASSED' if diag.passed else 'FAILED'}\")\n",
    "print()\n",
    "print(\n",
    "    f\"R-hat         max={diag.max_rhat:.4f}  threshold < {RHAT_THRESHOLD}  \"\n",
    "    f\"{'OK' if diag.rhat_ok else 'FAIL'}\"\n",
    ")\n",
    "print(\n",
    "    f\"ESS (bulk)    min={diag.min_ess:.0f}     threshold > {ESS_THRESHOLD}   \"\n",
    "    f\"{'OK' if diag.ess_ok else 'FAIL'}\"\n",
    ")\n",
    "print(\n",
    "    f\"Divergences   {diag.divergences}           threshold = 0      \"\n",
    "    f\"{'OK' if diag.divergences == 0 else 'FAIL'}\"\n",
    ")\n",
    "print()\n",
    "print(f\"Message: {diag.summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-summary-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full az.summary() for structural parameters only (exclude mu[date] rows)\n",
    "full_summary = az.summary(idata)\n",
    "param_mask = ~full_summary.index.str.startswith(\"mu[\")\n",
    "param_summary = full_summary[param_mask].copy()\n",
    "param_summary_sorted = param_summary.sort_values(\"r_hat\", ascending=False)\n",
    "\n",
    "display_cols = [\"mean\", \"sd\", \"hdi_3%\", \"hdi_97%\", \"ess_bulk\", \"r_hat\"]\n",
    "\n",
    "print(f\"Total parameters in model:        {len(full_summary)}\")\n",
    "print(f\"Structural parameters:            {len(param_summary)}\")\n",
    "print(\n",
    "    f\"With R-hat > {RHAT_THRESHOLD}:            \"\n",
    "    f\"{(param_summary['r_hat'] > RHAT_THRESHOLD).sum()}\"\n",
    ")\n",
    "print(\n",
    "    f\"With ESS (bulk) < {ESS_THRESHOLD}:         \"\n",
    "    f\"{(param_summary['ess_bulk'] < ESS_THRESHOLD).sum()}\"\n",
    ")\n",
    "print()\n",
    "print(\"Parameter summary (sorted by R-hat descending):\")\n",
    "param_summary_sorted[display_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s3-bar-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# R-hat bar chart\n",
    "rhat_values = param_summary_sorted[\"r_hat\"]\n",
    "rhat_colors = [\"tomato\" if r > RHAT_THRESHOLD else \"steelblue\" for r in rhat_values]\n",
    "rhat_values.plot.bar(ax=axes[0], color=rhat_colors, edgecolor=\"black\", linewidth=0.4)\n",
    "axes[0].axhline(\n",
    "    RHAT_THRESHOLD,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1.5,\n",
    "    label=f\"Threshold ({RHAT_THRESHOLD})\",\n",
    ")\n",
    "axes[0].set_title(\"R-hat per Structural Parameter\\n(red bars = failed threshold)\")\n",
    "axes[0].set_ylabel(\"R-hat\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=90, labelsize=7)\n",
    "axes[0].legend()\n",
    "\n",
    "# ESS bar chart\n",
    "ess_values = param_summary_sorted[\"ess_bulk\"]\n",
    "ess_colors = [\"tomato\" if e < ESS_THRESHOLD else \"steelblue\" for e in ess_values]\n",
    "ess_values.plot.bar(ax=axes[1], color=ess_colors, edgecolor=\"black\", linewidth=0.4)\n",
    "axes[1].axhline(\n",
    "    ESS_THRESHOLD,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1.5,\n",
    "    label=f\"Threshold ({ESS_THRESHOLD})\",\n",
    ")\n",
    "axes[1].set_title(\"ESS (bulk) per Structural Parameter\\n(red bars = failed threshold)\")\n",
    "axes[1].set_ylabel(\"ESS (bulk)\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=90, labelsize=7)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Convergence Metrics by Parameter\",\n",
    "    fontsize=13,\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Trace Plots\n",
    "\n",
    "Trace plots are the primary visual convergence diagnostic. Each plot shows two panels per parameter:\n",
    "\n",
    "- **Left (KDE):** Marginal posterior density per chain. Overlapping KDEs from all chains confirm they explored the same distribution.\n",
    "- **Right (trace):** Sample values over MCMC iterations. A converged chain looks like a **fuzzy caterpillar** — no trends, drift, or sticking. Chains that drift or separate indicate non-convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s4-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_params = [\"intercept\", \"adstock_alpha\", \"saturation_lam\", \"saturation_beta\"]\n",
    "\n",
    "az.plot_trace(idata, var_names=key_params, compact=True, figsize=(13, 10))\n",
    "plt.suptitle(\n",
    "    \"Trace Plots — Key Parameters\\n\"\n",
    "    \"LEFT: KDE per chain should overlap | RIGHT: trace should look like a fuzzy caterpillar\",\n",
    "    y=1.02,\n",
    "    fontsize=11,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Posterior Predictive Check\n",
    "\n",
    "A posterior predictive check (PPC) tests whether the fitted model can reproduce the observed data. Samples are drawn from $p(y^{\\text{rep}} \\mid y)$ — the posterior predictive distribution — and compared to the actual `total_gmv` time series. If the observed values fall consistently outside the predictive bands, the model is misspecified or the chains have not converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s5-ppc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample posterior predictive if not already present in idata\n",
    "if \"posterior_predictive\" not in list(idata.groups()):\n",
    "    print(\"Sampling posterior predictive (this may take a moment)...\")\n",
    "    sample_posterior_predictive(mmm, x)\n",
    "    idata = mmm.idata\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Posterior predictive already present in idata — skipping resampling.\")\n",
    "\n",
    "fig = mmm.plot_posterior_predictive(original_scale=True)\n",
    "if hasattr(fig, \"suptitle\"):\n",
    "    fig.suptitle(\n",
    "        \"Posterior Predictive Check\\n\"\n",
    "        \"Observed series should fall within the posterior predictive bands\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s6-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Prior vs Posterior\n",
    "\n",
    "Prior vs posterior plots reveal how much the data has updated the prior for each parameter. When the posterior closely tracks the prior (same shape, similar location), the likelihood is weak — the data is not strongly informative for that parameter. When the posterior is sharper or shifted relative to the prior, the data has overridden the prior and is driving inference.\n",
    "\n",
    "With only 12 effective monthly media patterns in the data, we expect many parameters to remain close to their priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adstock decay: Beta(1, 3) prior concentrates mass toward 0 (short-lived effects)\n",
    "# If the posterior shifts right (toward 1), data supports longer carryover\n",
    "fig = mmm.plot_prior_vs_posterior(\"adstock_alpha\", alphabetical_sort=True)\n",
    "plt.suptitle(\n",
    "    \"Adstock Decay (alpha): Prior vs Posterior\\n\"\n",
    "    \"Prior: Beta(1, 3). Posterior shift toward 1 = longer-lasting ad effect\",\n",
    "    fontsize=11,\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-lam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturation steepness: Gamma(3, 1) prior has mode at 2, mean at 3\n",
    "# Higher lam = faster saturation = diminishing returns kick in at lower spend levels\n",
    "fig = mmm.plot_prior_vs_posterior(\"saturation_lam\", alphabetical_sort=True)\n",
    "plt.suptitle(\n",
    "    \"Saturation Lambda (steepness): Prior vs Posterior\\n\"\n",
    "    \"Prior: Gamma(3, 1). Higher lam = faster saturation curve\",\n",
    "    fontsize=11,\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s6-beta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturation magnitude: HalfNormal(sigma=2) prior; loosely constrains channel contribution scale\n",
    "# Beta controls the maximum response a channel can contribute (in MaxAbsScaled target units)\n",
    "fig = mmm.plot_prior_vs_posterior(\"saturation_beta\", alphabetical_sort=True)\n",
    "plt.suptitle(\n",
    "    \"Saturation Beta (channel effect magnitude): Prior vs Posterior\\n\"\n",
    "    \"Prior: HalfNormal(sigma=2). Governs the maximum contribution per channel\",\n",
    "    fontsize=11,\n",
    "    y=1.02,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s7-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Channel Decomposition\n",
    "\n",
    "MMM decomposition breaks total GMV into additive components: baseline (intercept), each marketing channel's contribution, and control variable effects. The three plots below show decomposition from three perspectives: cumulative (waterfall), over time (contributions timeline), and as a share with uncertainty (HDI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s7-waterfall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall chart: cumulative average contribution per component\n",
    "fig = mmm.plot_waterfall_components_decomposition(original_scale=True, figsize=(14, 7))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s7-contributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel contributions over time with 94% HDI bands\n",
    "fig = mmm.plot_components_contributions()\n",
    "if hasattr(fig, \"suptitle\"):\n",
    "    fig.suptitle(\n",
    "        \"Channel Contributions Over Time (94% HDI)\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s7-share-hdi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel contribution share with 94% credible intervals\n",
    "# Wide HDI bands reflect genuine posterior uncertainty given the small effective sample size\n",
    "fig = mmm.plot_channel_contribution_share_hdi(hdi_prob=0.94)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s8-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Adstock Decay Curves\n",
    "\n",
    "GeometricAdstock applies exponential decay over time. The decay curve for a channel with parameter $\\alpha$ shows the fraction of the original spend effect that remains $k$ weeks later: $\\alpha^k$. A channel with $\\alpha = 0.5$ retains 50% of its effect after one week, 25% after two weeks, and so on up to `adstock_max_lag = 4` weeks. Posterior HDI bands reflect how well the data has constrained each channel's decay rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s8-posterior-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_alpha = az.summary(idata, var_names=[\"adstock_alpha\"])\n",
    "\n",
    "print(\"Adstock decay posterior estimates (adstock_alpha):\")\n",
    "print(\n",
    "    f\"{'Channel':<15} {'mean':>8} {'sd':>8} {'hdi_3%':>8} {'hdi_97%':>9} \"\n",
    "    f\"{'ess_bulk':>10} {'r_hat':>7}  Interpretation\"\n",
    ")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for param, row in summary_alpha.iterrows():\n",
    "    channel = param.replace(\"adstock_alpha[\", \"\").rstrip(\"]\")\n",
    "    alpha = row[\"mean\"]\n",
    "    remaining_wk1 = alpha * 100\n",
    "    remaining_wk2 = alpha**2 * 100\n",
    "    print(\n",
    "        f\"{channel:<15} {alpha:>8.3f} {row['sd']:>8.3f} {row['hdi_3%']:>8.3f} \"\n",
    "        f\"{row['hdi_97%']:>9.3f} {row['ess_bulk']:>10.0f} {row['r_hat']:>7.3f}  \"\n",
    "        f\"{remaining_wk1:.0f}% at wk+1, {remaining_wk2:.0f}% at wk+2\"\n",
    "    )\n",
    "\n",
    "print()\n",
    "print(f\"adstock_max_lag = {config.adstock_max_lag} weeks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s8-decay-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_max = config.adstock_max_lag\n",
    "weeks = np.arange(0, k_max + 1)\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(config.channel_columns)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for i, channel in enumerate(config.channel_columns):\n",
    "    param = f\"adstock_alpha[{channel}]\"\n",
    "    alpha_mean = summary_alpha.loc[param, \"mean\"]\n",
    "    alpha_lo = summary_alpha.loc[param, \"hdi_3%\"]\n",
    "    alpha_hi = summary_alpha.loc[param, \"hdi_97%\"]\n",
    "\n",
    "    decay_mean = alpha_mean**weeks * 100\n",
    "    decay_lo = alpha_lo**weeks * 100\n",
    "    decay_hi = alpha_hi**weeks * 100\n",
    "\n",
    "    ax.plot(\n",
    "        weeks,\n",
    "        decay_mean,\n",
    "        color=colors[i],\n",
    "        linewidth=2,\n",
    "        marker=\"o\",\n",
    "        label=f\"{channel} (alpha={alpha_mean:.2f})\",\n",
    "    )\n",
    "    ax.fill_between(weeks, decay_lo, decay_hi, alpha=0.18, color=colors[i])\n",
    "\n",
    "ax.set_xlabel(\"Weeks after spend\")\n",
    "ax.set_ylabel(\"% of original effect remaining\")\n",
    "ax.set_title(\n",
    "    f\"Adstock Decay Curves — Posterior Mean with 94% HDI\\n\"\n",
    "    f\"(GeometricAdstock, max_lag={k_max} weeks)\"\n",
    ")\n",
    "ax.set_ylim(0, 105)\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s9-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Saturation Response Curves\n",
    "\n",
    "LogisticSaturation models diminishing returns from increased channel spend. The response curve plots show, for each channel, the predicted contribution as a function of scaled spend (0 = no spend, 1 = maximum observed spend). The formula is $f(x) = \\beta \\cdot (2 \\sigma(\\lambda x) - 1)$ where $\\sigma$ is the logistic sigmoid. HDI bands reflect uncertainty in $\\lambda$ while holding $\\beta$ at its posterior mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s9-sat-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lam = az.summary(idata, var_names=[\"saturation_lam\"])\n",
    "summary_beta = az.summary(idata, var_names=[\"saturation_beta\"])\n",
    "\n",
    "print(\"Saturation parameter posterior estimates:\")\n",
    "print()\n",
    "print(\"saturation_lam (steepness — higher = faster saturation):\")\n",
    "display_cols = [\"mean\", \"sd\", \"hdi_3%\", \"hdi_97%\", \"ess_bulk\", \"r_hat\"]\n",
    "print(summary_lam[display_cols].to_string())\n",
    "print()\n",
    "print(\"saturation_beta (effect magnitude — scales max channel contribution):\")\n",
    "print(summary_beta[display_cols].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-s9-sat-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spend = np.linspace(0, 1, 200)  # MaxAbsScaled spend: 0 = no spend, 1 = max observed\n",
    "n_channels = len(config.channel_columns)\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, n_channels))\n",
    "\n",
    "fig, axes = plt.subplots(1, n_channels, figsize=(14, 4), sharey=False)\n",
    "\n",
    "for i, channel in enumerate(config.channel_columns):\n",
    "    lam_param = f\"saturation_lam[{channel}]\"\n",
    "    beta_param = f\"saturation_beta[{channel}]\"\n",
    "\n",
    "    lam_mean = summary_lam.loc[lam_param, \"mean\"]\n",
    "    lam_lo = summary_lam.loc[lam_param, \"hdi_3%\"]\n",
    "    lam_hi = summary_lam.loc[lam_param, \"hdi_97%\"]\n",
    "    beta_mean = summary_beta.loc[beta_param, \"mean\"]\n",
    "\n",
    "    y_mean = beta_mean * (2 * expit(lam_mean * x_spend) - 1)\n",
    "    y_lo = beta_mean * (2 * expit(lam_lo * x_spend) - 1)\n",
    "    y_hi = beta_mean * (2 * expit(lam_hi * x_spend) - 1)\n",
    "\n",
    "    axes[i].plot(x_spend, y_mean, color=colors[i], linewidth=2, label=\"Posterior mean\")\n",
    "    axes[i].fill_between(\n",
    "        x_spend, y_lo, y_hi, alpha=0.25, color=colors[i], label=\"94% HDI\"\n",
    "    )\n",
    "    axes[i].set_title(\n",
    "        f\"{channel}\\nlam={lam_mean:.2f}, beta={beta_mean:.2f}\", fontsize=9\n",
    "    )\n",
    "    axes[i].set_xlabel(\"Scaled spend (0=min, 1=max observed)\")\n",
    "    axes[i].set_ylabel(\"Contribution (scaled)\")\n",
    "    axes[i].legend(fontsize=7)\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Saturation Response Curves by Channel\\n\"\n",
    "    \"f(x) = beta * (2 * sigmoid(lam * x) - 1) — LogisticSaturation, inputs MaxAbsScaled\",\n",
    "    fontsize=11,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Steeper curves (higher lam) = diminishing returns kick in at lower spend levels.\\n\"\n",
    "    \"Wide HDI bands = the data is not strongly informative about the saturation shape.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-s10-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Model Limitations\n",
    "\n",
    "The following limitations should be understood when interpreting any results from this model:\n",
    "\n",
    "- **Effective N = 12.** Media spend (from `MediaInvestment.csv`) is only available at monthly granularity. All weeks within a month receive identical channel spend values via pro-rata distribution. The MCMC sampler therefore sees only 12 distinct media patterns — far fewer than the 52 weekly rows suggest. With 17 structural parameters and 12 effective observations, the posterior is prior-dominated for most channel-level parameters.\n",
    "\n",
    "- **Prior-dominated posteriors.** Because the likelihood is weak relative to the prior, the prior vs posterior plots (Section 6) will often show minimal updating. Posterior estimates for adstock decay, saturation steepness, and channel beta reflect our prior beliefs as much as the data. Results should not be treated as data-driven point estimates.\n",
    "\n",
    "- **Monthly spend distributed pro-rata across weeks.** Each week within a month receives an equal share of that month's total spend. This artificially smooths within-month spend variation and prevents the model from attributing GMV fluctuations within a month to media activity. Week-level attribution below the monthly grain is unreliable.\n",
    "\n",
    "- **Single market, single year.** The dataset covers one year (Jul 2015 – Jun 2016) for a single DT Mart market. The model cannot generalize across markets, geographies, or time periods outside this window. Structural shifts in channel effectiveness cannot be detected.\n",
    "\n",
    "- **No competitor or macroeconomic data.** External factors such as competitor promotions, price changes, and macroeconomic conditions are not included. Any effect they have on GMV will be absorbed by the intercept, control variables, or incorrectly attributed to marketing channels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
